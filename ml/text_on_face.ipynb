{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_text_on_face(image_path):\n",
    "    \"\"\"\n",
    "    Detects if there is text covering a person's face in the input image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the input image file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if text is detected on the face, False otherwise.\n",
    "    \"\"\"\n",
    "    # Load the Haar Cascade Classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale for face detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform face detection\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Convert the image to grayscale for OCR\n",
    "    gray_for_ocr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use pytesseract to extract text from the image\n",
    "    extracted_text = pytesseract.image_to_string(gray_for_ocr)\n",
    "\n",
    "    # Check if the extracted text overlaps with any of the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        if is_overlap_text_on_face(x, y, w, h, extracted_text):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlap_text_on_face(face_x, face_y, face_w, face_h, text):\n",
    "    \"\"\"\n",
    "    Checks if the extracted text overlaps with a given face.\n",
    "\n",
    "    Args:\n",
    "        face_x (int): X-coordinate of the face bounding box.\n",
    "        face_y (int): Y-coordinate of the face bounding box.\n",
    "        face_w (int): Width of the face bounding box.\n",
    "        face_h (int): Height of the face bounding box.\n",
    "        text (str): Extracted text from the image.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if text overlaps with the face, False otherwise.\n",
    "    \"\"\"\n",
    "    return face_x < len(text) < face_x + face_w and face_y < len(text) < face_y + face_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@803.067] global loadsave.cpp:248 findDecoder imread_('path/to/your/image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/fpfp2/Desktop/THWS/Project Module/Project_Module/ml/text_on_face.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpath/to/your/image.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m is_text_on_face(image_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[1;32m/Users/fpfp2/Desktop/THWS/Project Module/Project_Module/ml/text_on_face.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Convert the image to grayscale for face detection\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Perform face detection\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fpfp2/Desktop/THWS/Project%20Module/Project_Module/ml/text_on_face.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.3\u001b[39m, minNeighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image_path = \"path/to/your/image.jpg\"\n",
    "result = is_text_on_face(image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
